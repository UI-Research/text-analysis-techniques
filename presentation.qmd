---
title: "Text Analysis and NLP Techniques in Practice"
author: "Manu Alcal√° Kovalski and Judah Axelrod"
format: revealjs
editor: visual
title-slide-attributes: 
  data-background-image: www/images/urban-institute-logo.png
  data-background-size: 25%
  data-background-position: 8% 8%
output:
  html:
    number_sections: FALSE
    self_contained: TRUE
    code_folding: hide
    toc: TRUE
    toc_float: TRUE
    mathjax: null
    df_print: paged    
    css: !expr here::here("www", "web_report.css") 
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      include = TRUE,
                      tidy = TRUE,
                      cache = FALSE,
                      out.width = '100%',
                      out.height = '100%')
```

```{r}
#| include : false
librarian::shelf(tidyverse, tidytext, quanteda, reticulate, glue)
source('scripts/utils.R')
```

Load text from 27 Federal agency equity action plans
```{r}
# Read agency plans, convert text to a corpus, and tokenize
plans_txt <- readtext::readtext('data/txt/*', docvarsfrom = "filenames") |> filter(str_ends(doc_id, 'equity-action-plan.txt'))

plans <-
  fs::dir_ls('data/txt') |>
  fs::path_file() |>
  str_extract('^[^.]*') |>
  str_to_upper() |> 
  str_subset("EQUITY-ACTION-PLAN")

plans_txt

```

Convert to corpus object and split by sentences, words
```{r}
corpus <-
  corpus(plans_txt)|>
  set_names(plans) |>
  corpus_reshape(to = 'sentences')

 corpus(plans_txt)|>
  set_names(plans) |>
  corpus_reshape(to = 'paragraphs')

toks <- tokens(corpus, remove_punct = FALSE)
```


---

```{r}

dict_underserved <-
  dictionary(
    list(
      native_american = c('tribal*', 'tribes*', 'indigenous*','native*'),
      alaskan = 'alaskan*',
      pacific_islander = c('pacific*', 'pacific island*'),
      asian = c('asian'),
      aapi = c('aapi', 'asian-pacific'),
      black = c('black*', 'african-american*'),
      bipoc = 'BIPOC',
      poc = c('people of color', 'persons of color',  'students of color', 'Communities of color'),
      latinx = c('latino*', 'hispanic*', 'latinx*'),
      women = c('women'),
      lgbtqplus = c('LGBT*'),
      disabled = c('disabled*', 'disabilities*', 'disability*'),
      rural = c('rural*'),
      immigrant = c('immigrant*', 'newcomer*', 'migrant*')
    )
  )

dict_underserved_tidy <-
  tidy(dict_underserved) |>
  mutate(word = str_flatten(word, ', '))

underserved_global <-
  kwic(toks, dict_underserved, window = 1000) |>
  tidy_kwic() |>
  left_join(dict_underserved_tidy, by = c('pattern' = 'category'))


underserved_window <-
  tokens_select(toks, 'underserved*|disadvantaged|communities of concern|minority|overburdened|vulnerable|marginalized|underrepresented', window = 1000, selection = 'keep') |>
  kwic(dict_underserved, window = 1000) |>
  tidy_kwic() |>
  left_join(dict_underserved_tidy, by = c('pattern' = 'category'))
```
---

```{r}



dict_barriers <- dictionary(list(barriers = c('completion', 'enroll*', 'participat*')))
barriers_window <-
  tokens_select(toks, 'barrier*', window = 1000, selection = 'keep') |>
  kwic(dict_barriers, window = 1000) |>
  tidy_kwic() |>
  mutate(search_terms = str_flatten(dict_barriers$barriers, ', ')) |>
  distinct(agency, plan, sentence_number, .keep_all = TRUE)


```


```

